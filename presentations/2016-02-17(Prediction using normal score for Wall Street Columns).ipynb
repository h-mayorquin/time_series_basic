{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using normal score for Wall Street Columns\n",
    "In this notebook we extract we compare how the good are the features when we allow some mix in time and when we compell them to be independent. We use this features to make a simple prediction tasks where each example has to predict its own letter and use the prediction as a means of comparison for the quality of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, cross_validation\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data to use\n",
    "Ndata = 10000\n",
    "\n",
    "# First we load the file \n",
    "file_location = '../results_database/text_wall_street_columns.hdf5'\n",
    "\n",
    "\n",
    "# Now we need to get the letters and align them\n",
    "text_directory = '../data/wall_street_letters.npy'\n",
    "letters_sequence = np.load(text_directory)\n",
    "Nletters = len(letters_sequence)\n",
    "symbols = set(letters_sequence)\n",
    "\n",
    "targets = []\n",
    "\n",
    "for index in range(Ndata):\n",
    "    letter_index = index // 10\n",
    "    targets.append(letters_sequence[letter_index])\n",
    "\n",
    "# Transform to array\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the loop and calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the predictions    \n",
    "Ntime_clusters_set = np.arange(3, 50, 3)   \n",
    "\n",
    "scores_mixed = []\n",
    "scores_indp = []\n",
    "\n",
    "# Nexa parameters\n",
    "Nspatial_clusters = 3\n",
    "Nembedding = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for Ntime_clusters in Ntime_clusters_set:\n",
    "    print(Ntime_clusters)\n",
    "    # Here calculate the scores for the mixes\n",
    "    run_name = '/test'\n",
    "    f = h5py.File(file_location, 'r')\n",
    "\n",
    "    parameters_string = '/' + str(Nspatial_clusters)\n",
    "    parameters_string += '-' + str(Ntime_clusters)\n",
    "    parameters_string += '-' + str(Nembedding)\n",
    "\n",
    "    nexa = f[run_name + parameters_string]\n",
    "    cluster_to_index = nexa['cluster_to_index']\n",
    "    code_vectors_softmax = np.array(nexa['code-vectors-softmax'])\n",
    "\n",
    "    # Now we need to classify\n",
    "    X  = code_vectors_softmax[:Ndata]\n",
    "    y = targets\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "    clf_linear = svm.SVC(C=1.0, kernel='linear')\n",
    "    clf_linear.fit(X_train, y_train)\n",
    "    score = clf_linear.score(X_test, y_test) * 100.0\n",
    "    scores_mixed.append(score)\n",
    "\n",
    "    # Here calculate the scores for the independent\n",
    "    run_name = '/indep'\n",
    "    f = h5py.File(file_location, 'r')\n",
    "    \n",
    "    parameters_string = '/' + str(Nspatial_clusters)\n",
    "    parameters_string += '-' + str(Ntime_clusters)\n",
    "    parameters_string += '-' + str(Nembedding)\n",
    "\n",
    "    nexa = f[run_name + parameters_string]\n",
    "    cluster_to_index = nexa['cluster_to_index']\n",
    "    code_vectors_softmax = np.array(nexa['code-vectors-softmax'])\n",
    "\n",
    "    # Now we need to classify\n",
    "    X  = code_vectors_softmax[:Ndata]\n",
    "    y = targets\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "    clf_linear = svm.SVC(C=1.0, kernel='linear')\n",
    "    clf_linear.fit(X_train, y_train)\n",
    "    score = clf_linear.score(X_test, y_test) * 100.0\n",
    "    scores_indp.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(Ntime_clusters_set, scores_indp, 'o-', label='independent', lw=2, markersize=10)\n",
    "ax.plot(Ntime_clusters_set, scores_mixed, 'o-', label='mixed', lw=2, markersize=10)\n",
    "\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Data Clusters')\n",
    "ax.set_title('Accuracy vs Number of Data Clusters for different features')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now without spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data to use\n",
    "Ndata = 10000\n",
    "\n",
    "# First we load the file \n",
    "file_location = '../results_database/text_wall_street_columns_spaces.hdf5'\n",
    "\n",
    "\n",
    "# Now we need to get the letters and align them\n",
    "text_directory = '../data/wall_street_letters_spaces.npy'\n",
    "letters_sequence = np.load(text_directory)\n",
    "Nletters = len(letters_sequence)\n",
    "symbols = set(letters_sequence)\n",
    "\n",
    "targets = []\n",
    "\n",
    "for index in range(Ndata):\n",
    "    letter_index = index // 10\n",
    "    targets.append(letters_sequence[letter_index])\n",
    "\n",
    "# Transform to array\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the loop and calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the predictions    \n",
    "Ntime_clusters_set = np.arange(3, 50, 3)   \n",
    "\n",
    "scores_mixed_wspaces = []\n",
    "scores_indp_wspaces = []\n",
    "\n",
    "# Nexa parameters\n",
    "Nspatial_clusters = 3\n",
    "Nembedding = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for Ntime_clusters in Ntime_clusters_set:\n",
    "    print(Ntime_clusters)\n",
    "    # Here calculate the scores for the mixes\n",
    "    run_name = '/test'\n",
    "    f = h5py.File(file_location, 'r')\n",
    "\n",
    "    parameters_string = '/' + str(Nspatial_clusters)\n",
    "    parameters_string += '-' + str(Ntime_clusters)\n",
    "    parameters_string += '-' + str(Nembedding)\n",
    "\n",
    "    nexa = f[run_name + parameters_string]\n",
    "    cluster_to_index = nexa['cluster_to_index']\n",
    "    code_vectors_softmax = np.array(nexa['code-vectors-softmax'])\n",
    "\n",
    "    # Now we need to classify\n",
    "    X  = code_vectors_softmax[:Ndata]\n",
    "    y = targets\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "    clf_linear = svm.SVC(C=1.0, kernel='linear')\n",
    "    clf_linear.fit(X_train, y_train)\n",
    "    score = clf_linear.score(X_test, y_test) * 100.0\n",
    "    scores_mixed_wspaces.append(score)\n",
    "\n",
    "    # Here calculate the scores for the independent\n",
    "    run_name = '/indep'\n",
    "    f = h5py.File(file_location, 'r')\n",
    "    \n",
    "    parameters_string = '/' + str(Nspatial_clusters)\n",
    "    parameters_string += '-' + str(Ntime_clusters)\n",
    "    parameters_string += '-' + str(Nembedding)\n",
    "\n",
    "    nexa = f[run_name + parameters_string]\n",
    "    cluster_to_index = nexa['cluster_to_index']\n",
    "    code_vectors_softmax = np.array(nexa['code-vectors-softmax'])\n",
    "\n",
    "    # Now we need to classify\n",
    "    X  = code_vectors_softmax[:Ndata]\n",
    "    y = targets\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "    clf_linear = svm.SVC(C=1.0, kernel='linear')\n",
    "    clf_linear.fit(X_train, y_train)\n",
    "    score = clf_linear.score(X_test, y_test) * 100.0\n",
    "    scores_indp_wspaces.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(Ntime_clusters_set, scores_indp, 'o-', label='independent', lw=2, markersize=10)\n",
    "ax.plot(Ntime_clusters_set, scores_mixed, 'o-', label='mixed', lw=2, markersize=10)\n",
    "\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Data Clusters')\n",
    "ax.set_title('Accuracy vs Number of Data Clusters for different features (Without Sapces)')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
